# Awesome-Robotics-Foundation-Models [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

This repository offers a curated collection of research papers on **Robotics Foundation Models** and **Generalist Robot Policies**, exploring how these approaches contribute to the advancement of embodied AI. The goal is to provide researchers and practitioners with  the latest methodologies and foundational works driving progress in the field.


## Table of Contents
- [Awesome-Robotics-Foundation Models ](#awesome-robotics-foundation-models)
    - [Table of Contents](#table-of-contents)
    - [Datasets, Simulators, Benchmarks \& Surveys](#datasets-benchmarks--surveys)
    - [Foundation Models used for Robotics](#foundation-models-used-for-robotics)
    - [Generalist Robot Policies](#generalist-robot-policies)
    - [Applications](#applications)
    - [Others](#others)
    - [Open-Sourced Works](#open-sourced-works)

## Datasets, Simulators, Benchmarks & Surveys

<!-- (*'23*)
[[project page]( ])] [[paper]()] -->

## Foundation Models used for Robotics
(Git Repo) Awesome Generalist Robots via Foundation Models [[Paper List](https://github.com/JeffreyYH/Awesome-Generalist-Robots-via-Foundation-Models)]
## Generalist Robot Policies

### 2022
(*CoRL'22*) Do As I Can, Not As I Say: Grounding Language in Robotic Affordances [[project page](https://say-can.github.io/])] [[paper](https://arxiv.org/abs/2204.01691p)]


(*CoRL'22*) Inner Monologue: Embodied Reasoning through Planning with Language Models [[project page](https://innermonologue.github.io/])] [[paper](https://arxiv.org/abs/2207.05608)]

### 2023

(*RSS'23*) RT-1: Robotics Transformer for Real-World Control at Scale  [[project page](https://robotics-transformer1.github.io/])] [[paper](https://arxiv.org/abs/2212.06817)]

(*CoRL'23*) Open-World Object Manipulation using Pre-trained Vision-Language Models
[[project page](https://robot-moo.github.io/])] [[paper](https://arxiv.org/abs/2303.00905)]

(*arxiv 23.07*) RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control
[[project page](https://robotics-transformer2.github.io/])] [[paper](https://arxiv.org/abs/2307.15818)]

(*arxiv 23.11*) (RoboFlamingo) Vision-Language Foundation Models as Effective Robot Imitators 
[[project page](https://roboflamingo.github.io/])] [[paper](https://arxiv.org/abs/2311.01378)]

(*ICLR'24*) RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches
[[project page](https://rt-trajectory.github.io/])] [[paper](https://arxiv.org/abs/2311.01977)]

(*ICLR'24*) (GR-1) Unleashing Large-Scale Video Generative Pre-training for Visual Robot Manipulation
[[project page](https://gr1-manipulation.github.io/])] [[paper](https://arxiv.org/html/2312.13139)]


### 2024

(*arxiv 24.03*) RT-H: Action Hierarchies Using Language
[[project page](https://rt-hierarchy.github.io/])] [[paper](https://arxiv.org/abs/2403.01823)]

(*RSS'24*) Octo: An Open-Source Generalist Robot Policy
[[project page](https://octo-models.github.io/])] [[paper](https://arxiv.org/abs/2405.12213)]

(*CoRL'24*) OpenVLA: An Open-Source Vision-Language-Action Model
[[project page](https://openvla.github.io/])] [[paper](https://arxiv.org/abs/2406.09246)]

(*arxiv'24.09*) TinyVLA: Towards Fast, Data-Efficient Vision-Language-Action Models for Robotic Manipulation
[[project page](https://tiny-vla.github.io/])] [[paper](https://arxiv.org/abs/2409.12514)]

(*arxiv 24.10*) GR-2: A Generative Video-Language-Action Model with Web-Scale Knowledge for Robot Manipulation
[[project page](https://gr2-manipulation.github.io/])] [[paper](https://arxiv.org/abs/2410.06158)]

(*arxiv 24.10*) RDT-1B: A Diffusion Foundation Model for Bimanual Manipulation
[[project page]( ])] [[paper](https://arxiv.org/abs/2410.07864)]

## Applications

## Others

## Open-Sourced Works

## Contributing
üëç Contributions to this repository are welcome! 

If you have come across relevant resources, feel free to open an issue or submit a pull request.
```
- (*conference|journal*) paper_name [[pdf](link)][[code](link)]p